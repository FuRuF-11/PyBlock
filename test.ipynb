{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import dataset,dataloader \n",
    "import torch.optim as optim\n",
    "from Transformer import Transformer\n",
    "from Transformer import Encoder,EncoderBlock\n",
    "from Transformer import Decoder,DecoderBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    # head number of Multi-head attention\n",
    "    \"head_num\": 8,\n",
    "    \"batch_size\": 64,\n",
    "    # source sentence length\n",
    "    \"src_length\": 50,\n",
    "    # traget sentence length\n",
    "    \"trg_length\": 40,\n",
    "    # layer size of encoder and decoder\n",
    "    \"layer_size\": 8,\n",
    "    # dropout rate\n",
    "    \"dropout\": 0.3,\n",
    "    # learning rate\n",
    "    \"lr\": 0.001,\n",
    "    \"max_length\": 100 \n",
    "}\n",
    "# input word embedding size which should be the times number of head_num\n",
    "config[\"d_model\"]=config[\"head_num\"]*50\n",
    "# hidden_size of hidden layers in MLP\n",
    "config[\"hidden_size\"]=2*config[\"d_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 40, 400])\n"
     ]
    }
   ],
   "source": [
    "a=torch.ones(config[\"batch_size\"],config[\"src_length\"],config[\"d_model\"])\n",
    "b=torch.ones(config[\"batch_size\"],config[\"trg_length\"],config[\"d_model\"])\n",
    "c=torch.zeros(config[\"d_model\"])\n",
    "a[:,-2:]=c\n",
    "b[:,-3:]=c\n",
    "# tmp1=(a.sum(dim=2)==0)\n",
    "# tmp2=(b.sum(dim=2)==0)\n",
    "# mask=get_attn_pad_mask(tmp1,tmp1)\n",
    "# mask=get_attn_pad_mask(tmp2,tmp2)\n",
    "# mask=get_attn_pad_mask(tmp2,tmp1)\n",
    "# print(mask.size())\n",
    "# print(mask[0])\n",
    "Tran=Transformer(config)\n",
    "res=Tran(a,b)\n",
    "print(res.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m a[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\u001b[38;5;241m=\u001b[39mc\n\u001b[0;32m      7\u001b[0m b[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m:]\u001b[38;5;241m=\u001b[39mc\n\u001b[1;32m----> 8\u001b[0m res\u001b[38;5;241m=\u001b[39m\u001b[43mTran\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(res\u001b[38;5;241m.\u001b[39msize())\n",
      "File \u001b[1;32md:\\DataScience\\Env\\DL2024\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\transformer.py:39\u001b[0m, in \u001b[0;36mTransformer.generate\u001b[1;34m(self, sentnece1, sentnece2, max_length)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m,sentnece1,sentnece2,max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    we need two different sentences to run the transformr\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    and the second sentnece need to be finished \u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     mask1\u001b[38;5;241m=\u001b[39m\u001b[43msourceMask\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentnece1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     en_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(sentnece1,mask1)\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_length):\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\attention.py:30\u001b[0m, in \u001b[0;36msourceMask\u001b[1;34m(src1, src2)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(src2\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     29\u001b[0m      src2\u001b[38;5;241m=\u001b[39msrc1\n\u001b[1;32m---> 30\u001b[0m src1\u001b[38;5;241m=\u001b[39m(\u001b[43msrc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     31\u001b[0m src2\u001b[38;5;241m=\u001b[39m(src2\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m batch_size, len_q \u001b[38;5;241m=\u001b[39m src1\u001b[38;5;241m.\u001b[39msize()\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "config[\"end_word\"]=c\n",
    "config[\"max_length\"]=20\n",
    "a=torch.ones(config[\"src_length\"],config[\"d_model\"])\n",
    "b=torch.ones(10,config[\"d_model\"])\n",
    "c=torch.zeros(config[\"d_model\"])\n",
    "a[-2:]=c\n",
    "b[-3:]=c\n",
    "res=Tran.generate(a,b,config[\"max_length\"])\n",
    "print(res.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
