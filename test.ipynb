{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import dataset,dataloader \n",
    "import torch.optim as optim\n",
    "from Transformer import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m example\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m50\u001b[39m,\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m Tran\u001b[38;5;241m=\u001b[39m\u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m Tran(example)\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\transformer.py:39\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, d_model, layer_size, head, pad, dropout, max_length)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03md_model: the dims of every vector\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03mlayer_size=6: the layer size of encoder/decoder\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03mmax_length=2000: the maximum allowed length of sentences in position encoder\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28msuper\u001b[39m(Transformer,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m=\u001b[39m\u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlayer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m=\u001b[39mDecoder(d_model,layer_size,head,dropout,max_length)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(d_model,d_model,bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\encoder.py:30\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[1;34m(self, d_model, layer_size, head, dropout, max_length)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN\u001b[38;5;241m=\u001b[39mlayer_size\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition\u001b[38;5;241m=\u001b[39mCosinPosition(d_model,max_length,dropout)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m=\u001b[39mcloneLayers(\u001b[43mEncoderBlock\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mLayerNorm(d_model)\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\encoder.py:18\u001b[0m, in \u001b[0;36mEncoderBlock.__init__\u001b[1;34m(self, d_model, head, dropout)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNorm2\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mLayerNorm(d_model)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention\u001b[38;5;241m=\u001b[39mSelfAttention(d_model,head,dropout)\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeedforward\u001b[38;5;241m=\u001b[39m\u001b[43mMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\furuf\\Desktop\\workspace\\PyBlock\\Transformer\\feedforward.py:26\u001b[0m, in \u001b[0;36mMLP.__init__\u001b[1;34m(self, in_feature, hidden, dropout)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,in_feature,hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28msuper\u001b[39m(MLP,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMLP\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     25\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLayerNorm(in_feature),\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhidden\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_feature\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     27\u001b[0m         NewGELU(),\n\u001b[0;32m     28\u001b[0m         nn\u001b[38;5;241m.\u001b[39mLinear(hidden\u001b[38;5;241m*\u001b[39min_feature,in_feature)\n\u001b[0;32m     29\u001b[0m     )\n",
      "File \u001b[1;32md:\\DataScience\\Env\\DL2024\\lib\\site-packages\\torch\\nn\\modules\\linear.py:96\u001b[0m, in \u001b[0;36mLinear.__init__\u001b[1;34m(self, in_features, out_features, bias, device, dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_features \u001b[38;5;241m=\u001b[39m in_features\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features \u001b[38;5;241m=\u001b[39m out_features\n\u001b[1;32m---> 96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty((out_features, in_features), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bias:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m Parameter(torch\u001b[38;5;241m.\u001b[39mempty(out_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs))\n",
      "\u001b[1;31mTypeError\u001b[0m: empty() received an invalid combination of arguments - got (tuple, dtype=NoneType, device=NoneType), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.memory_format memory_format, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, torch.memory_format memory_format, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "example=torch.randn(64,50,50)\n",
    "Tran=Transformer(d_model=50)\n",
    "Tran(example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
